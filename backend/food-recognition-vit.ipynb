{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-09T07:31:30.478597Z",
     "iopub.status.busy": "2025-06-09T07:31:30.477895Z",
     "iopub.status.idle": "2025-06-09T07:34:35.642602Z",
     "shell.execute_reply": "2025-06-09T07:34:35.641891Z",
     "shell.execute_reply.started": "2025-06-09T07:31:30.478571Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input contains 0 files\n",
      "/kaggle/input/chinese-food-175-dataset contains 1 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175 contains 0 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175 contains 1 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Á∫¢ÁÉßÂÜ¨Áìú contains 140 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Ë±âÊ±ÅËí∏Âá§Áà™ contains 294 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Á∫¢ÁÉßË±ÜËÖê contains 287 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/È∫ªËæ£Ë±ÜËÖê contains 279 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ÂÜ¨ÁìúÊéíÈ™®Ê±§ contains 291 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Ëë±ÁàÜÁæäËÇâ contains 290 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Ê∏ÖÁÇíËä•Ëìù contains 283 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Âú∞ÈîÖÈ∏° contains 280 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ËÇâÊú´ËåÑÂ≠ê contains 272 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Âç§È∏°Áà™ contains 285 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ËöùÊ≤πÈ∏°ÁøÖ contains 265 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Ê∞¥ÁÖÆËÇâÁâá contains 293 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Ëç∑Â°òÂ∞èÁÇí contains 293 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Êú®È°ªËÇâ contains 295 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Ëæ£Â≠êÈ∏°‰∏Å contains 286 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ÁÇíÁå™ËÇù contains 293 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Á∫¢ÁÉßÁâõËÖ© contains 282 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ÈªÑÁÑñÊéíÈ™® contains 291 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Ê∏ÖËí∏È≤´È±º contains 271 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ÈùíÊ§íÁÇíËÇâ‰∏ù contains 287 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Âπ≤ÈîÖËä±Ëèú contains 290 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Âπ≤ÈîÖË±ÜËÖê contains 283 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ÂáâÊãåÊµ∑Â∏¶‰∏ù contains 294 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ÈÖ∏Ëæ£ÂúüË±Ü‰∏ù contains 298 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Ë±ÜËÖêÁÖ≤ contains 295 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ÁôΩÂàáÈ∏° contains 296 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Á±≥È•≠ contains 54 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ÂÖ∞Â∑ûÁâõËÇâÈù¢ contains 183 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Ë±ÜË±âÁÇíËõ§Ëúä contains 265 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Á≥ñÈÜãÈ±º contains 295 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ÂíïÂôúËÇâ contains 294 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/È±ºÈ¶ôË±ÜËÖê contains 280 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ËõãËä±Ê±§ contains 283 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ÈÖ∏ËèúÁôΩËÇâ contains 267 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/È±ºÂ§¥Ê≥°È•º contains 231 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ÂáâÊãåÈªÑÁìú contains 288 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Âç§È∏°Ëõã contains 288 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/È¶ôÂπ≤ÁÇíËÇâ‰∏ù contains 268 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Ëôæ‰ªÅË±ÜËÖê contains 279 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Èõ™ËèúÁÇíÂÜ¨Á¨ã contains 252 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ËíúËìâÊ≤πÈ∫¶Ëèú contains 285 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/È±ºÈ¶ôËÇâ‰∏ù contains 298 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ËõãÁÇíÈ•≠ contains 171 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/È∫ªËæ£ÂÖî‰∏Å contains 295 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/È∫ªËæ£È¶ôÈîÖ contains 291 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ËíúËãóÁÇíËÇâ contains 289 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ÈÖ±ÁàÜËåÑÂ≠ê contains 281 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ÈÖ∏ËèúÈ±º contains 298 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Á∫¢ÁÉßÁå™ËπÑ contains 289 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ÂÆ´‰øùËôæÁêÉ contains 279 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Ë±ÜË±âËí∏ÊéíÈ™® contains 281 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Á∫¢ÁÉßÈ≤§È±º contains 295 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Êú®ËÄ≥ÁÇíÈ∏°Ëõã contains 275 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ÁÇ∏È∏°Âùó contains 278 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ÈÖ±È¶ôËåÑÂ≠ê contains 275 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Âπ≤ÈîÖËôæ contains 286 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/È±ºÈ¶ôÈ∏°‰∏ù contains 244 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Âπ≤ÁÖ∏Ë±ÜËßí contains 298 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Âè£Ê∞¥È∏° contains 96 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Á∫¢ÁÉßÂ∏¶È±º contains 292 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ÁâõÊéí contains 66 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ÈÖ∏ËèúÁÇíÁ≤â‰∏ù contains 187 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/È∫ªÂ©ÜË±ÜËÖê contains 298 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Á≥ñÈÜãÈáåËÑä contains 295 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ÂâÅÊ§íËí∏ÊéíÈ™® contains 248 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Âπ≤ÁÖ∏ÁâõËÇâ contains 50 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ÂÆ∂Â∏∏Ë±ÜËÖê contains 290 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ÂõûÈîÖËÇâ contains 299 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ÁÇíÈ∏°ÂøÉ contains 275 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Âç§Áå™ËπÑ contains 298 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ÁÇíÈùíÊ§í contains 259 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ÈÖ∏Ëæ£Ê±§ contains 296 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/È¶ôËèáÁÇíÈ∏° contains 266 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Âπ≤ÈîÖÈ∏° contains 296 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ÈÖ∏Ëæ£Á≤â contains 297 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Âπ≤ÈîÖÁâõËõô contains 284 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ÈÖ∏Ëæ£È±º contains 281 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Âç§Ê∞¥ÊãºÁõò contains 280 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Âπ≤ÁÖ∏È∏°‰∏Å contains 161 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/È±ºÂ§¥Ë±ÜËÖêÊ±§ contains 283 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Ëæ£Ê§íÁÇíËÇâ contains 294 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ËíúÈ¶ôÊéíÈ™® contains 299 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Ëë±Ê≤πÊãåÈù¢ contains 295 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ÈÖ±ÁÉßËåÑÂ≠ê contains 274 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Á∫¢ÁÉßÈ∏°ÁøÖ contains 289 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ÁÇùÊãåÂúüË±Ü‰∏ù contains 296 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Ê§íÁõêËôæ contains 294 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Ë±ÜË±âÈ≤ÆÈ±ºÁÇíËã¶Áìú contains 237 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ËíúËìâÁÇíËôæ contains 131 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Ê¢ÖËèúÊâ£ËÇâ contains 297 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Âí∏ËõãÈªÑÁÑóÂçóÁìú contains 289 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Á∫¢ÁÉßÈ±º contains 298 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/È¶ôËæ£Ëôæ contains 288 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ËöùÊ≤πÁîüËèú contains 292 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ÁÇùÁÇíÁôΩËèú contains 260 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ÈùíËä±Ê§íÈ±º contains 171 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Á∫¢ÁÉßÁâõËÇâÈù¢ contains 156 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ÈÖ∏Ëæ£Ëôæ contains 270 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ËÇâÊú´Ë±ÜËÖê contains 271 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ÁàÜÁÇíËÖ∞Ëä± contains 279 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ÁôΩÁÅºËôæ contains 294 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Ëä±Ê§íÈ∏° contains 270 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Ë±ÜË±âÁÇíËã¶Áìú contains 278 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Á∫¢ÁÉßËåÑÂ≠ê contains 290 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ËöÇËöÅ‰∏äÊ†ë contains 288 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Âπ≤ÈîÖÂúüË±ÜÁâá contains 297 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Ëë±Ê≤πÈ∏° contains 293 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Ë±ÜË±âÈ∏°‰∏Å contains 199 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Ëôæ‰ªÅÁÇíËõã contains 274 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ÁõêÁÑóÈ∏° contains 255 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/È¶ôËæ£Ëüπ contains 279 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ÈÖ∏Ëæ£ËóïÁâá contains 272 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ÊØõË°ÄÊó∫ contains 299 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ÈÖ∏Ëæ£ËÇ•ËÇ† contains 255 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Ê∏ÖËí∏È≤àÈ±º contains 294 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ÁÇ∏È≤úÂ•∂ contains 288 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Âú∞‰∏âÈ≤ú contains 297 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Á≤âËí∏ÊéíÈ™® contains 289 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/È¶ôËèáÁÑñÈ∏° contains 264 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ËÖê‰π≥ËÇâÁâá contains 281 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ÂâÅÊ§íÈ±ºÂ§¥ contains 296 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Á∫¢ÁÉßËÇâ contains 298 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ËíúËìâÁÇíË•øÂÖ∞Ëä± contains 285 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Á∫¢ÁÉßÁãÆÂ≠êÂ§¥ contains 285 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Á≥ñÈÜãÊéíÈ™® contains 292 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ËöùÊ≤πÁâõËÇâ contains 284 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ÁÇíÈªÑË±ÜËäΩ contains 293 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Á∫¢ÁÉßÊéíÈ™® contains 294 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Ë•øÁ∫¢ÊüøÁÇíËôæ‰ªÅ contains 173 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/È¶ôËèáÁÇñÊéíÈ™® contains 223 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Ëæ£ÁôΩËèúÁÇíËÇâ contains 271 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ÂÆ´‰øùÈ∏°‰∏Å contains 300 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Ëë±Ëä±ÁÇíËõã contains 198 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ÂáâÊãåÊú®ËÄ≥ contains 292 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Á∫¢ÁÉßÈ∏≠ contains 241 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Ëí∏Ëõã contains 292 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ÁÇíÈùíËèú contains 282 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/È¶ôËèáÁÇñÈ∏° contains 245 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Â≠úÁÑ∂ÁæäËÇâ contains 277 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Áï™ËåÑÁÇíËõã contains 290 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ÈªÑÁÑñÈ∏°Á±≥È•≠ contains 274 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ËôéÁöÆÈùíÊ§í contains 282 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/È∫ªËæ£È∏°Âùó contains 257 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ÁÇíÈ¶ôÂπ≤ contains 280 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/È¶ôËèáÁÇíÈùíËèú contains 275 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/È±ºÈ¶ôËåÑÂ≠ê contains 289 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Ëä±ÈõïÈ∏° contains 259 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/È∫ªËæ£È∏≠ËÑñ contains 286 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Ë±ÜËÖêËÑë contains 296 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Ê∞¥ÁÖÆÈ±º contains 298 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Áï™ËåÑÁâõËÖ© contains 291 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Ê∏ÖËí∏Â§ßÈó∏Ëüπ contains 289 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ËíúËìâÁ≤â‰∏ùËí∏ÊâáË¥ù contains 276 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ÂâÅÊ§íÈ±º contains 275 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ËêùÂçúÁÇñÁâõËÇâ contains 294 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Ê∏ÖÁÇíË•øÂÖ∞Ëä± contains 286 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ËíúËìâÁîüËèú contains 271 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Á≤âËí∏ËÇâ contains 295 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/È∫ªËæ£ÁÉ§È±º contains 295 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ÁÇíËä¶Á¨ã contains 273 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ÁÇ∏ÈÖ±Èù¢ contains 283 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Âπ≤ÈîÖËèúËä± contains 281 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Á∫¢ÁÉßÈ∏°ËÖø contains 278 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ÁÇíË±åË±Ü contains 244 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Ëæ£Ê§íÁÇíËõã contains 278 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Âπ≤ÁÖ∏ÂõõÂ≠£Ë±Ü contains 292 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ËÖê‰π≥Á©∫ÂøÉËèú contains 276 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Á∫¢ÁÉßÈ≤´È±º contains 290 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Âπ≤ÁÖ∏ÁâõËÇâ‰∏ù contains 281 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/È∫ªËæ£ÁâõËÇâ contains 288 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Ëë±ÂßúÁÇíËüπ contains 280 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/Á≥ñÈÜãË±ÜËÖê contains 276 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ÈÖ∏ËèúË±ÜËÖêÊ±§ contains 275 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/È¶ôËæ£ÁâõËõô contains 287 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/ÂáâÊãåË±ÜËÖêÁöÆ contains 285 files\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    print(f\"{dirname} contains {len(filenames)} files\")\n",
    "\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T07:35:45.990605Z",
     "iopub.status.busy": "2025-06-09T07:35:45.989908Z",
     "iopub.status.idle": "2025-06-09T07:36:00.827143Z",
     "shell.execute_reply": "2025-06-09T07:36:00.826526Z",
     "shell.execute_reply.started": "2025-06-09T07:35:45.990578Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries successfully imported.\n",
      "üé≤ Random seeds set for reproducibility.\n",
      "üñ•Ô∏è Using device: cuda:0 - Tesla T4\n",
      "üíæ GPU Memory: 14.7 GB\n",
      "üìÅ Dataset root directory: /kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175\n",
      "‚ö†Ô∏è Font 'WenQuanYi Zen Hei' not found. Installing...\n",
      "üîÅ Font installed.\n",
      "üñãÔ∏è Font configured: WenQuanYi Zen Hei\n",
      "\n",
      "‚úÖ Cell 1: Enhanced initialization complete.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 1: Enhanced Initialization and Setup\n",
    "# =============================================================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.font_manager as fm\n",
    "import subprocess\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Libraries successfully imported.\")\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "print(\"üé≤ Random seeds set for reproducibility.\")\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f\"üñ•Ô∏è Using device: {device} - {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "else:\n",
    "    print(f\"üñ•Ô∏è Using device: {device}\")\n",
    "\n",
    "base_data_dir = '/kaggle/input/chinese-food-175-dataset'\n",
    "data_root_dir = os.path.join(base_data_dir, 'chinese-food-175', 'chinese-food-175')\n",
    "print(f\"üìÅ Dataset root directory: {data_root_dir}\")\n",
    "\n",
    "font_name = 'WenQuanYi Zen Hei'\n",
    "font_found = any(font_name in f.name for f in fm.fontManager.ttflist)\n",
    "if not font_found:\n",
    "    print(f\"‚ö†Ô∏è Font '{font_name}' not found. Installing...\")\n",
    "    subprocess.run([\"apt-get\", \"update\"], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "    subprocess.run([\"apt-get\", \"install\", \"-y\", \"fonts-wqy-zenhei\"], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "    print(\"üîÅ Font installed.\")\n",
    "else:\n",
    "    print(f\"‚úÖ Font '{font_name}' already available.\")\n",
    "\n",
    "try:\n",
    "    font_path = fm.findfont(fm.FontProperties(family=font_name), fontext='ttf')\n",
    "    fe = fm.FontEntry(fname=font_path, name=font_name)\n",
    "    fm.fontManager.ttflist.insert(0, fe)\n",
    "    plt.rcParams.update({'font.family': fe.name, 'font.sans-serif': fe.name})\n",
    "    print(f\"üñãÔ∏è Font configured: {fe.name}\")\n",
    "except:\n",
    "    print(\"‚ö†Ô∏è Font setup failed, using default font.\")\n",
    "\n",
    "print(\"\\n‚úÖ Cell 1: Enhanced initialization complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 2: CONFIGURATION AND DATA PREPARATION\n",
    "# =============================================================================\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision.transforms import AutoAugment, AutoAugmentPolicy\n",
    "import torch\n",
    "\n",
    "data_root_dir = '/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"üåç Using device: {device}\")\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=20),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    AutoAugment(AutoAugmentPolicy.IMAGENET),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomErasing(p=0.2, scale=(0.02, 0.20)),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "print(\"‚úÖ success.\")\n",
    "\n",
    "\n",
    "full_dataset = datasets.ImageFolder(data_root_dir)\n",
    "class_names = full_dataset.classes\n",
    "num_classes = len(class_names)\n",
    "print(f\"üîç Dataset found it. class total: {num_classes}\")\n",
    "\n",
    "train_indices, val_indices = train_test_split(\n",
    "    list(range(len(full_dataset))),\n",
    "    test_size=0.2,\n",
    "    stratify=full_dataset.targets,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "class DatasetWithTransform(torch.utils.data.Dataset):\n",
    "    def __init__(self, subset, transform):\n",
    "        self.subset = subset\n",
    "        self.transform = transform\n",
    "    def __getitem__(self, index):\n",
    "        x, y = self.subset[index]\n",
    "        return self.transform(x), y\n",
    "    def __len__(self):\n",
    "        return len(self.subset)\n",
    "\n",
    "train_dataset = DatasetWithTransform(torch.utils.data.Subset(full_dataset, train_indices), train_transforms)\n",
    "val_dataset = DatasetWithTransform(torch.utils.data.Subset(full_dataset, val_indices), val_transforms)\n",
    "\n",
    "batch_size = 32\n",
    "num_workers = 2\n",
    "dataloaders = {\n",
    "    'train': torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True),\n",
    "    'val': torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "}\n",
    "dataset_sizes = {'train': len(train_dataset), 'val': len(val_dataset)}\n",
    "print(\"‚úÖ Dataloader for training ready to use.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T20:02:08.717630Z",
     "iopub.status.busy": "2025-06-07T20:02:08.717385Z",
     "iopub.status.idle": "2025-06-07T20:02:08.738479Z",
     "shell.execute_reply": "2025-06-07T20:02:08.737927Z",
     "shell.execute_reply.started": "2025-06-07T20:02:08.717611Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 3: DEFINITION MODEL AND TRAINING CONFIGURATION\n",
    "# =============================================================================\n",
    "from torchvision.models import EfficientNet_B4_Weights\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "print(\"üöÄ Memuat arsitektur EfficientNet-B4...\")\n",
    "weights = EfficientNet_B4_Weights.IMAGENET1K_V1\n",
    "model_ft = models.efficientnet_b4(weights=weights)\n",
    "\n",
    "num_ftrs = model_ft.classifier[1].in_features\n",
    "model_ft.classifier = nn.Sequential(\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(num_ftrs, 512),\n",
    "    nn.BatchNorm1d(512),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(512, num_classes)\n",
    ")\n",
    "model_ft = model_ft.to(device)\n",
    "print(\"üîß Classifier head already modified.\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer_ft = optim.AdamW(model_ft.parameters(), lr=3e-4, weight_decay=1e-4)\n",
    "scheduler_ft = lr_scheduler.CosineAnnealingLR(optimizer_ft, T_max=50, eta_min=1e-6)\n",
    "print(\"‚úÖ Loss, optimizer, and scheduler already configure.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T20:02:08.739421Z",
     "iopub.status.busy": "2025-06-07T20:02:08.739198Z",
     "iopub.status.idle": "2025-06-07T20:02:09.972137Z",
     "shell.execute_reply": "2025-06-07T20:02:09.971391Z",
     "shell.execute_reply.started": "2025-06-07T20:02:08.739406Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 4: MAIN TRAINING FUNCTION\n",
    "# =============================================================================\n",
    "import time\n",
    "import copy\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25, patience=5):\n",
    "    since = time.time()\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    epochs_no_improve = 0\n",
    "    \n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "    \n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'\\nEpoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 20)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            \n",
    "            progress_bar = tqdm(dataloaders[phase], desc=f\"{phase.capitalize()} Epoch {epoch+1}\", leave=False)\n",
    "\n",
    "            for inputs, labels in progress_bar:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        scaler.scale(loss).backward()\n",
    "                        scaler.step(optimizer)\n",
    "                        scaler.update()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f'{phase.upper()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "            \n",
    "            if phase == 'train':\n",
    "                history['train_loss'].append(epoch_loss)\n",
    "                history['train_acc'].append(epoch_acc.item())\n",
    "            else:\n",
    "                history['val_loss'].append(epoch_loss)\n",
    "                history['val_acc'].append(epoch_acc.item())\n",
    "                \n",
    "                if epoch_acc > best_acc:\n",
    "                    print(f\"üéâ accuracy improve : ({best_acc:.4f} --> {epoch_acc:.4f}). Menyimpan model...\")\n",
    "                    best_acc = epoch_acc\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                    epochs_no_improve = 0\n",
    "                else:\n",
    "                    epochs_no_improve += 1\n",
    "\n",
    "        if phase == 'train' and scheduler:\n",
    "             scheduler.step()\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"\\nüõë Early stopping! no improvement {patience} epoch.\")\n",
    "            break\n",
    "            \n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'\\nTraining Complete {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'üèÜ Best Accuracy: {best_acc:.4f}')\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, history\n",
    "\n",
    "print(\"‚úÖ Main Training Function Ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T20:02:09.973333Z",
     "iopub.status.busy": "2025-06-07T20:02:09.973022Z",
     "iopub.status.idle": "2025-06-07T20:02:09.990806Z",
     "shell.execute_reply": "2025-06-07T20:02:09.989999Z",
     "shell.execute_reply.started": "2025-06-07T20:02:09.973305Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 5: TRAINING AND SAVING MODEL\n",
    "# =============================================================================\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"\\nüöÄ Running Process Started...\")\n",
    "model_ft_trained, training_history = train_model(\n",
    "    model_ft, \n",
    "    criterion, \n",
    "    optimizer_ft, \n",
    "    scheduler_ft, \n",
    "    num_epochs=15, \n",
    "    patience=5\n",
    ")\n",
    "\n",
    "best_val_acc = max(training_history['val_acc'])\n",
    "print(f\"Best Accuracy: {best_val_acc*100:.2f}%\")\n",
    "\n",
    "final_model_path = 'best_model_food_classifier.pth'\n",
    "print(f\"Saving Best Model: {final_model_path}\")\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': model_ft_trained.state_dict(),\n",
    "    'best_val_acc': best_val_acc,\n",
    "    'class_names': class_names,\n",
    "    'val_transforms_code': str(val_transforms) \n",
    "}, final_model_path)\n",
    "\n",
    "print(f\"‚úÖ Model Saved '{final_model_path}'. Already To Download!\")\n",
    "\n",
    "def plot_training_history(history):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history['train_acc'], label='Train Accuracy')\n",
    "    plt.plot(history['val_acc'], label='Validation Accuracy')\n",
    "    plt.title('Accuracy vs. Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history['train_loss'], label='Train Loss')\n",
    "    plt.plot(history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Loss vs. Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\nüìä Showing Grafik Training...\")\n",
    "plot_training_history(training_history)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7334294,
     "sourceId": 11753786,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
