{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-09T07:31:30.478597Z",
     "iopub.status.busy": "2025-06-09T07:31:30.477895Z",
     "iopub.status.idle": "2025-06-09T07:34:35.642602Z",
     "shell.execute_reply": "2025-06-09T07:34:35.641891Z",
     "shell.execute_reply.started": "2025-06-09T07:31:30.478571Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input contains 0 files\n",
      "/kaggle/input/chinese-food-175-dataset contains 1 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175 contains 0 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175 contains 1 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/红烧冬瓜 contains 140 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/豉汁蒸凤爪 contains 294 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/红烧豆腐 contains 287 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/麻辣豆腐 contains 279 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/冬瓜排骨汤 contains 291 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/葱爆羊肉 contains 290 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/清炒芥蓝 contains 283 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/地锅鸡 contains 280 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/肉末茄子 contains 272 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/卤鸡爪 contains 285 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/蚝油鸡翅 contains 265 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/水煮肉片 contains 293 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/荷塘小炒 contains 293 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/木须肉 contains 295 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/辣子鸡丁 contains 286 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/炒猪肝 contains 293 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/红烧牛腩 contains 282 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/黄焖排骨 contains 291 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/清蒸鲫鱼 contains 271 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/青椒炒肉丝 contains 287 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/干锅花菜 contains 290 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/干锅豆腐 contains 283 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/凉拌海带丝 contains 294 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/酸辣土豆丝 contains 298 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/豆腐煲 contains 295 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/白切鸡 contains 296 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/米饭 contains 54 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/兰州牛肉面 contains 183 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/豆豉炒蛤蜊 contains 265 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/糖醋鱼 contains 295 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/咕噜肉 contains 294 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/鱼香豆腐 contains 280 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/蛋花汤 contains 283 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/酸菜白肉 contains 267 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/鱼头泡饼 contains 231 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/凉拌黄瓜 contains 288 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/卤鸡蛋 contains 288 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/香干炒肉丝 contains 268 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/虾仁豆腐 contains 279 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/雪菜炒冬笋 contains 252 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/蒜蓉油麦菜 contains 285 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/鱼香肉丝 contains 298 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/蛋炒饭 contains 171 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/麻辣兔丁 contains 295 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/麻辣香锅 contains 291 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/蒜苗炒肉 contains 289 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/酱爆茄子 contains 281 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/酸菜鱼 contains 298 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/红烧猪蹄 contains 289 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/宫保虾球 contains 279 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/豆豉蒸排骨 contains 281 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/红烧鲤鱼 contains 295 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/木耳炒鸡蛋 contains 275 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/炸鸡块 contains 278 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/酱香茄子 contains 275 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/干锅虾 contains 286 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/鱼香鸡丝 contains 244 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/干煸豆角 contains 298 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/口水鸡 contains 96 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/红烧带鱼 contains 292 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/牛排 contains 66 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/酸菜炒粉丝 contains 187 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/麻婆豆腐 contains 298 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/糖醋里脊 contains 295 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/剁椒蒸排骨 contains 248 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/干煸牛肉 contains 50 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/家常豆腐 contains 290 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/回锅肉 contains 299 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/炒鸡心 contains 275 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/卤猪蹄 contains 298 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/炒青椒 contains 259 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/酸辣汤 contains 296 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/香菇炒鸡 contains 266 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/干锅鸡 contains 296 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/酸辣粉 contains 297 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/干锅牛蛙 contains 284 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/酸辣鱼 contains 281 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/卤水拼盘 contains 280 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/干煸鸡丁 contains 161 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/鱼头豆腐汤 contains 283 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/辣椒炒肉 contains 294 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/蒜香排骨 contains 299 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/葱油拌面 contains 295 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/酱烧茄子 contains 274 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/红烧鸡翅 contains 289 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/炝拌土豆丝 contains 296 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/椒盐虾 contains 294 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/豆豉鲮鱼炒苦瓜 contains 237 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/蒜蓉炒虾 contains 131 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/梅菜扣肉 contains 297 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/咸蛋黄焗南瓜 contains 289 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/红烧鱼 contains 298 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/香辣虾 contains 288 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/蚝油生菜 contains 292 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/炝炒白菜 contains 260 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/青花椒鱼 contains 171 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/红烧牛肉面 contains 156 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/酸辣虾 contains 270 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/肉末豆腐 contains 271 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/爆炒腰花 contains 279 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/白灼虾 contains 294 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/花椒鸡 contains 270 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/豆豉炒苦瓜 contains 278 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/红烧茄子 contains 290 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/蚂蚁上树 contains 288 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/干锅土豆片 contains 297 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/葱油鸡 contains 293 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/豆豉鸡丁 contains 199 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/虾仁炒蛋 contains 274 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/盐焗鸡 contains 255 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/香辣蟹 contains 279 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/酸辣藕片 contains 272 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/毛血旺 contains 299 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/酸辣肥肠 contains 255 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/清蒸鲈鱼 contains 294 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/炸鲜奶 contains 288 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/地三鲜 contains 297 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/粉蒸排骨 contains 289 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/香菇焖鸡 contains 264 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/腐乳肉片 contains 281 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/剁椒鱼头 contains 296 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/红烧肉 contains 298 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/蒜蓉炒西兰花 contains 285 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/红烧狮子头 contains 285 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/糖醋排骨 contains 292 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/蚝油牛肉 contains 284 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/炒黄豆芽 contains 293 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/红烧排骨 contains 294 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/西红柿炒虾仁 contains 173 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/香菇炖排骨 contains 223 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/辣白菜炒肉 contains 271 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/宫保鸡丁 contains 300 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/葱花炒蛋 contains 198 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/凉拌木耳 contains 292 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/红烧鸭 contains 241 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/蒸蛋 contains 292 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/炒青菜 contains 282 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/香菇炖鸡 contains 245 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/孜然羊肉 contains 277 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/番茄炒蛋 contains 290 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/黄焖鸡米饭 contains 274 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/虎皮青椒 contains 282 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/麻辣鸡块 contains 257 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/炒香干 contains 280 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/香菇炒青菜 contains 275 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/鱼香茄子 contains 289 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/花雕鸡 contains 259 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/麻辣鸭脖 contains 286 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/豆腐脑 contains 296 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/水煮鱼 contains 298 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/番茄牛腩 contains 291 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/清蒸大闸蟹 contains 289 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/蒜蓉粉丝蒸扇贝 contains 276 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/剁椒鱼 contains 275 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/萝卜炖牛肉 contains 294 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/清炒西兰花 contains 286 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/蒜蓉生菜 contains 271 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/粉蒸肉 contains 295 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/麻辣烤鱼 contains 295 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/炒芦笋 contains 273 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/炸酱面 contains 283 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/干锅菜花 contains 281 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/红烧鸡腿 contains 278 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/炒豌豆 contains 244 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/辣椒炒蛋 contains 278 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/干煸四季豆 contains 292 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/腐乳空心菜 contains 276 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/红烧鲫鱼 contains 290 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/干煸牛肉丝 contains 281 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/麻辣牛肉 contains 288 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/葱姜炒蟹 contains 280 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/糖醋豆腐 contains 276 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/酸菜豆腐汤 contains 275 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/香辣牛蛙 contains 287 files\n",
      "/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175/凉拌豆腐皮 contains 285 files\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    print(f\"{dirname} contains {len(filenames)} files\")\n",
    "\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T07:35:45.990605Z",
     "iopub.status.busy": "2025-06-09T07:35:45.989908Z",
     "iopub.status.idle": "2025-06-09T07:36:00.827143Z",
     "shell.execute_reply": "2025-06-09T07:36:00.826526Z",
     "shell.execute_reply.started": "2025-06-09T07:35:45.990578Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Libraries successfully imported.\n",
      "🎲 Random seeds set for reproducibility.\n",
      "🖥️ Using device: cuda:0 - Tesla T4\n",
      "💾 GPU Memory: 14.7 GB\n",
      "📁 Dataset root directory: /kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175\n",
      "⚠️ Font 'WenQuanYi Zen Hei' not found. Installing...\n",
      "🔁 Font installed.\n",
      "🖋️ Font configured: WenQuanYi Zen Hei\n",
      "\n",
      "✅ Cell 1: Enhanced initialization complete.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 1: Enhanced Initialization and Setup\n",
    "# =============================================================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.font_manager as fm\n",
    "import subprocess\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✅ Libraries successfully imported.\")\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "print(\"🎲 Random seeds set for reproducibility.\")\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f\"🖥️ Using device: {device} - {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"💾 GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "else:\n",
    "    print(f\"🖥️ Using device: {device}\")\n",
    "\n",
    "base_data_dir = '/kaggle/input/chinese-food-175-dataset'\n",
    "data_root_dir = os.path.join(base_data_dir, 'chinese-food-175', 'chinese-food-175')\n",
    "print(f\"📁 Dataset root directory: {data_root_dir}\")\n",
    "\n",
    "font_name = 'WenQuanYi Zen Hei'\n",
    "font_found = any(font_name in f.name for f in fm.fontManager.ttflist)\n",
    "if not font_found:\n",
    "    print(f\"⚠️ Font '{font_name}' not found. Installing...\")\n",
    "    subprocess.run([\"apt-get\", \"update\"], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "    subprocess.run([\"apt-get\", \"install\", \"-y\", \"fonts-wqy-zenhei\"], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "    print(\"🔁 Font installed.\")\n",
    "else:\n",
    "    print(f\"✅ Font '{font_name}' already available.\")\n",
    "\n",
    "try:\n",
    "    font_path = fm.findfont(fm.FontProperties(family=font_name), fontext='ttf')\n",
    "    fe = fm.FontEntry(fname=font_path, name=font_name)\n",
    "    fm.fontManager.ttflist.insert(0, fe)\n",
    "    plt.rcParams.update({'font.family': fe.name, 'font.sans-serif': fe.name})\n",
    "    print(f\"🖋️ Font configured: {fe.name}\")\n",
    "except:\n",
    "    print(\"⚠️ Font setup failed, using default font.\")\n",
    "\n",
    "print(\"\\n✅ Cell 1: Enhanced initialization complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 2: CONFIGURATION AND DATA PREPARATION\n",
    "# =============================================================================\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision.transforms import AutoAugment, AutoAugmentPolicy\n",
    "import torch\n",
    "\n",
    "data_root_dir = '/kaggle/input/chinese-food-175-dataset/chinese-food-175/chinese-food-175'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"🌍 Using device: {device}\")\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=20),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    AutoAugment(AutoAugmentPolicy.IMAGENET),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomErasing(p=0.2, scale=(0.02, 0.20)),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "print(\"✅ success.\")\n",
    "\n",
    "\n",
    "full_dataset = datasets.ImageFolder(data_root_dir)\n",
    "class_names = full_dataset.classes\n",
    "num_classes = len(class_names)\n",
    "print(f\"🔍 Dataset found it. class total: {num_classes}\")\n",
    "\n",
    "train_indices, val_indices = train_test_split(\n",
    "    list(range(len(full_dataset))),\n",
    "    test_size=0.2,\n",
    "    stratify=full_dataset.targets,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "class DatasetWithTransform(torch.utils.data.Dataset):\n",
    "    def __init__(self, subset, transform):\n",
    "        self.subset = subset\n",
    "        self.transform = transform\n",
    "    def __getitem__(self, index):\n",
    "        x, y = self.subset[index]\n",
    "        return self.transform(x), y\n",
    "    def __len__(self):\n",
    "        return len(self.subset)\n",
    "\n",
    "train_dataset = DatasetWithTransform(torch.utils.data.Subset(full_dataset, train_indices), train_transforms)\n",
    "val_dataset = DatasetWithTransform(torch.utils.data.Subset(full_dataset, val_indices), val_transforms)\n",
    "\n",
    "batch_size = 32\n",
    "num_workers = 2\n",
    "dataloaders = {\n",
    "    'train': torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True),\n",
    "    'val': torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "}\n",
    "dataset_sizes = {'train': len(train_dataset), 'val': len(val_dataset)}\n",
    "print(\"✅ Dataloader for training ready to use.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T20:02:08.717630Z",
     "iopub.status.busy": "2025-06-07T20:02:08.717385Z",
     "iopub.status.idle": "2025-06-07T20:02:08.738479Z",
     "shell.execute_reply": "2025-06-07T20:02:08.737927Z",
     "shell.execute_reply.started": "2025-06-07T20:02:08.717611Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 3: DEFINITION MODEL AND TRAINING CONFIGURATION\n",
    "# =============================================================================\n",
    "from torchvision.models import EfficientNet_B4_Weights\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "print(\"🚀 Memuat arsitektur EfficientNet-B4...\")\n",
    "weights = EfficientNet_B4_Weights.IMAGENET1K_V1\n",
    "model_ft = models.efficientnet_b4(weights=weights)\n",
    "\n",
    "num_ftrs = model_ft.classifier[1].in_features\n",
    "model_ft.classifier = nn.Sequential(\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(num_ftrs, 512),\n",
    "    nn.BatchNorm1d(512),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(512, num_classes)\n",
    ")\n",
    "model_ft = model_ft.to(device)\n",
    "print(\"🔧 Classifier head already modified.\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer_ft = optim.AdamW(model_ft.parameters(), lr=3e-4, weight_decay=1e-4)\n",
    "scheduler_ft = lr_scheduler.CosineAnnealingLR(optimizer_ft, T_max=50, eta_min=1e-6)\n",
    "print(\"✅ Loss, optimizer, and scheduler already configure.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T20:02:08.739421Z",
     "iopub.status.busy": "2025-06-07T20:02:08.739198Z",
     "iopub.status.idle": "2025-06-07T20:02:09.972137Z",
     "shell.execute_reply": "2025-06-07T20:02:09.971391Z",
     "shell.execute_reply.started": "2025-06-07T20:02:08.739406Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 4: MAIN TRAINING FUNCTION\n",
    "# =============================================================================\n",
    "import time\n",
    "import copy\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25, patience=5):\n",
    "    since = time.time()\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    epochs_no_improve = 0\n",
    "    \n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "    \n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'\\nEpoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 20)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            \n",
    "            progress_bar = tqdm(dataloaders[phase], desc=f\"{phase.capitalize()} Epoch {epoch+1}\", leave=False)\n",
    "\n",
    "            for inputs, labels in progress_bar:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        scaler.scale(loss).backward()\n",
    "                        scaler.step(optimizer)\n",
    "                        scaler.update()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f'{phase.upper()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "            \n",
    "            if phase == 'train':\n",
    "                history['train_loss'].append(epoch_loss)\n",
    "                history['train_acc'].append(epoch_acc.item())\n",
    "            else:\n",
    "                history['val_loss'].append(epoch_loss)\n",
    "                history['val_acc'].append(epoch_acc.item())\n",
    "                \n",
    "                if epoch_acc > best_acc:\n",
    "                    print(f\"🎉 accuracy improve : ({best_acc:.4f} --> {epoch_acc:.4f}). Menyimpan model...\")\n",
    "                    best_acc = epoch_acc\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                    epochs_no_improve = 0\n",
    "                else:\n",
    "                    epochs_no_improve += 1\n",
    "\n",
    "        if phase == 'train' and scheduler:\n",
    "             scheduler.step()\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"\\n🛑 Early stopping! no improvement {patience} epoch.\")\n",
    "            break\n",
    "            \n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'\\nTraining Complete {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'🏆 Best Accuracy: {best_acc:.4f}')\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, history\n",
    "\n",
    "print(\"✅ Main Training Function Ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T20:02:09.973333Z",
     "iopub.status.busy": "2025-06-07T20:02:09.973022Z",
     "iopub.status.idle": "2025-06-07T20:02:09.990806Z",
     "shell.execute_reply": "2025-06-07T20:02:09.989999Z",
     "shell.execute_reply.started": "2025-06-07T20:02:09.973305Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 5: TRAINING AND SAVING MODEL\n",
    "# =============================================================================\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"\\n🚀 Running Process Started...\")\n",
    "model_ft_trained, training_history = train_model(\n",
    "    model_ft, \n",
    "    criterion, \n",
    "    optimizer_ft, \n",
    "    scheduler_ft, \n",
    "    num_epochs=15, \n",
    "    patience=5\n",
    ")\n",
    "\n",
    "best_val_acc = max(training_history['val_acc'])\n",
    "print(f\"Best Accuracy: {best_val_acc*100:.2f}%\")\n",
    "\n",
    "final_model_path = 'best_model_food_classifier.pth'\n",
    "print(f\"Saving Best Model: {final_model_path}\")\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': model_ft_trained.state_dict(),\n",
    "    'best_val_acc': best_val_acc,\n",
    "    'class_names': class_names,\n",
    "    'val_transforms_code': str(val_transforms) \n",
    "}, final_model_path)\n",
    "\n",
    "print(f\"✅ Model Saved '{final_model_path}'. Already To Download!\")\n",
    "\n",
    "def plot_training_history(history):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history['train_acc'], label='Train Accuracy')\n",
    "    plt.plot(history['val_acc'], label='Validation Accuracy')\n",
    "    plt.title('Accuracy vs. Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history['train_loss'], label='Train Loss')\n",
    "    plt.plot(history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Loss vs. Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\n📊 Showing Grafik Training...\")\n",
    "plot_training_history(training_history)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7334294,
     "sourceId": 11753786,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
